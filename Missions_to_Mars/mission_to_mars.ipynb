{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def init_browser():\n",
    "    # @NOTE: Replace the path with your actual path to the chromedriver\n",
    "    executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)\n",
    "\n",
    "\n",
    "\n",
    "def scrape_info():\n",
    "\n",
    "    #run above function 'init_browser'\n",
    "    browser = init_browser()\n",
    "\n",
    "    # Scrape the NASA Mars News Site and collect the latest News\n",
    "    url = \"https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest\"\n",
    "    browser.visit(url)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Scrape page into Soup\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    # Get the News Info Section\n",
    "    news_info = soup.find('div', class_='list_text')\n",
    "    #print(news_info.text)\n",
    "\n",
    "    # collect the latest News Title\n",
    "    news_sec1 = news_info.find('div', class_='content_title')\n",
    "    news_title = news_sec1.a.text\n",
    "    #print(news_title)\n",
    "\n",
    "    # news article Paragraph Text\n",
    "    news_p = news_info.find('div', class_=\"article_teaser_body\").text\n",
    "    #print(news_p)\n",
    "\n",
    "    # Close the browser after scraping\n",
    "    browser.quit()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### LETS GET THE JPL IMAGE!!\n",
    "    # Visit the url for JPL Featured Space Image here\n",
    "\n",
    "    # run above function 'init_browser'\n",
    "    browser = init_browser()\n",
    "\n",
    "    url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "    browser.visit(url)\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Scrape page into Soup\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "\n",
    "    # Use splinter to click on main 'full image' button\n",
    "    image_button = browser.find_by_id('full_image')\n",
    "\n",
    "    image_button.click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Clicking 'more info' button. Making way to large image info\n",
    "    browser.find_by_css(\".buttons .button\").click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    # image url for the current Featured Mars Image\n",
    "    browser.find_by_css(\".lede\").click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    # assign the url string to a variable called featured_image_url\n",
    "    featured_image_url = browser.url\n",
    "\n",
    "    # Close the browser after scraping\n",
    "    browser.quit()\n",
    "\n",
    "    \n",
    "    \n",
    "    ### LETS GET THE MARS FUN FACTS!!\n",
    "\n",
    "    #run above function 'init_browser'\n",
    "    browser = init_browser()\n",
    "\n",
    "    url = \"https://space-facts.com/mars/\"\n",
    "    browser.visit(url)\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Scrape page into Soup\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    # Turn any site table into a pandas object\n",
    "    tables = pd.read_html(url)\n",
    "\n",
    "    # Close the browser after scraping\n",
    "    browser.quit()\n",
    "\n",
    "    # make the pandas table object a dataframe and make sure it's the 1st table\n",
    "    df = tables[0]\n",
    "    ## remove index\n",
    "    df.set_index([0], inplace=True)\n",
    "    df\n",
    "\n",
    "    # Just making sure there are non column labels\n",
    "    df.columns.name = None\n",
    "    df\n",
    "\n",
    "    ## HTML tables from DataFrames\n",
    "    mars_facts = df.to_html()\n",
    "    mars_facts\n",
    "\n",
    "\n",
    "\n",
    "    ## LETS GET THE MARS hemisphere images\n",
    "\n",
    "    browser = init_browser()\n",
    "\n",
    "    url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "    browser.visit(url)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Scrape page into Soup\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    # main_url \n",
    "    main_url = 'https://astrogeology.usgs.gov'\n",
    "\n",
    "    # the section of the page with all the mars hemi's\n",
    "    items = soup.find_all('div', class_='item')\n",
    "\n",
    "    # The empty list of to-be dictionaries \n",
    "    hemi_urls = []\n",
    "\n",
    "    ## Loop through the section of mars images and titles\n",
    "    #interesting that 'i' in the loop acts like 'soup' but as the iterator. Took me awhile to get my\n",
    "    #head around that concept.\n",
    "    for i in items: \n",
    "        # Store title\n",
    "        title = i.find('h3').text\n",
    "\n",
    "        # Just the full image url\n",
    "        just_img_url = i.find('a', class_='itemLink product-item')['href']\n",
    "\n",
    "        # go to full image url\n",
    "        browser.visit(main_url + just_img_url)\n",
    "\n",
    "        # store html \n",
    "        img_html = browser.html\n",
    "\n",
    "        soup = bs( img_html, 'html.parser')\n",
    "\n",
    "        # get full image\n",
    "        img_url = main_url + soup.find('img', class_='wide-image')['src']\n",
    "\n",
    "        # Append the retreived information into a list of dictionaries \n",
    "        hemi_urls.append({\"title\" : title, \"img_url\" : img_url})\n",
    "\n",
    "    browser.quit()\n",
    "    # see list\n",
    "    hemi_urls\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## This section is connected in the app.py\n",
    "    \n",
    "    # Store data in a dictionary\n",
    "    image_dict = hemi_urls\n",
    "    \n",
    "    mars_data = {\n",
    "        \"news_title\": news_title,\n",
    "        \"news_p\": news_p,\n",
    "        \"featured_image_url\": featured_image_url,\n",
    "        \"mars_facts\": mars_facts,\n",
    "    }\n",
    "\n",
    "\n",
    "    return mars_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
